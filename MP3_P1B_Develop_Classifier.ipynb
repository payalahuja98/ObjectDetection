{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "colab": {
      "name": "MP3_P1B_Develop_Classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/payalahuja98/ObjectDetection/blob/main/MP3_P1B_Develop_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kq7qSMtH8lKR"
      },
      "source": [
        "# Assignment 3 Part 1: Developing Your Own Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YE6aUyWFw5pb",
        "outputId": "1ba64d1e-2852-4fc8-9ccb-019cf631c609",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rqo2klvJrDoR",
        "outputId": "a9de9be1-4c4c-4842-a4d6-4661135d0d11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        }
      },
      "source": [
        "# # Check cuda version on colab and run the following PyTorch installation commands respectively.\n",
        "# RUN IF \n",
        "# 1. RuntimeError: each element in list of batch should be of equal size\n",
        "\n",
        "# Check cuda version on colab and run the following PyTorch installation commands respectively.\n",
        "!nvcc --version\n",
        "\n",
        "# If CUDA 10.2 is installed\n",
        "# !pip install torch==1.5.1 torchvision==0.6.1\n",
        "\n",
        "# If CUDA 10.1 is installed \n",
        "!pip install torch==1.5.1+cu101 torchvision==0.6.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# If CUDA 9.2 is installed\n",
        "# !pip install torch==1.5.1 torchvision==0.6.1\n",
        "\n",
        "# If CUDA 10.1 is installed \n",
        "# !pip install torch==1.5.1+cu101 torchvision==0.6.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# If CUDA 9.2 is installed\n",
        "# !pip install torch==1.5.1+cu92 torchvision==0.6.1+cu92 -f https://download.pytorch.org/whl/torch_stable.htmlion\n",
        "# !pip install torch==1.5.1+cu101 torchvision==0.6.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "Cuda compilation tools, release 10.1, V10.1.243\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Requirement already satisfied: torch==1.5.1+cu101 in /usr/local/lib/python3.6/dist-packages (1.5.1+cu101)\n",
            "Requirement already satisfied: torchvision==0.6.1+cu101 in /usr/local/lib/python3.6/dist-packages (0.6.1+cu101)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.5.1+cu101) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.5.1+cu101) (1.18.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.6.1+cu101) (7.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maEkFAIO8lKS",
        "outputId": "c212a17f-e8bb-484c-b1b8-0e23019dd0cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/My Drive/FA2020/CS498/assignment3_p1_starterkit.zip (Unzipped Files)/assignment3_p1_starterkit')\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "\n",
        "from torchvision import transforms\n",
        "from sklearn.metrics import average_precision_score\n",
        "from PIL import Image, ImageDraw\n",
        "import matplotlib.pyplot as plt\n",
        "from kaggle_submission import output_submission_csv\n",
        "# from classifier import SimpleClassifier, Classifier#, AlexNet\n",
        "from voc_dataloader import VocDataset, VOC_CLASSES\n",
        "\n",
        "from imgaug import augmenters as iaa\n",
        "import imgaug as ia\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGFPWS4Fq4Kg",
        "outputId": "3f310e7b-4b53-48a8-ed74-1713277d1235",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import shutil \n",
        "shutil.copyfile(\"VOCtrainval_06-Nov-2007.tar\", \"/content/VOCtrainval_06-Nov-2007.tar\")\n",
        "!tar -xf \"/content/VOCtrainval_06-Nov-2007.tar\" -C \"/content/\" \n",
        "shutil.move(\"/content/VOCdevkit/\", \"/content/VOCdevkit_2007\")\n",
        "\n",
        "shutil.copyfile(\"VOCtest_06-Nov-2007.tar\", \"/content/VOCtest_06-Nov-2007.tar\")\n",
        "!tar -xf \"/content/VOCtest_06-Nov-2007.tar\" -C \"/content/\" \n",
        "shutil.move(\"/content/VOCdevkit/VOC2007\", \"/content/VOCdevkit_2007/VOC2007test\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/VOCdevkit_2007/VOC2007test'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64Lwzx3o8lKX"
      },
      "source": [
        "# Part 1B: Design your own network\n",
        "\n",
        "In this notebook, your task is to create and train your own model for multi-label classification on VOC Pascal.\n",
        "\n",
        "## What to do\n",
        "1. You will make change on network architecture in ```classifier.py```.\n",
        "2. You may also want to change other hyperparameters to assist your training to get a better performances. Hints will be given in the below instructions.\n",
        "\n",
        "## What to submit\n",
        "Check the submission template for details what to submit. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yrMVMf_sJFf"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "import numpy as np\n",
        "\n",
        "NUM_CLASSES = 21\n",
        "\n",
        "class Alexnet(nn.Module):\n",
        "  def __init__(self):\n",
        "      super(Alexnet, self).__init__()\n",
        "      self.conv1 = nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2)\n",
        "      self.conv2 = nn.Conv2d(64, 192, kernel_size=5, padding=2)\n",
        "      self.conv3 = nn.Conv2d(192, 384, kernel_size=3, padding=1)\n",
        "      self.conv4 = nn.Conv2d(384, 256, kernel_size=3, padding=1)\n",
        "      self.conv5 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
        "      self.pool = nn.MaxPool2d(kernel_size=2)\n",
        "      self.fc1 = nn.Linear(256 * 6 * 6, 4096)\n",
        "      self.fc2 = nn.Linear(4096, 4096)\n",
        "      self.fc3 = nn.Linear(4096, NUM_CLASSES)\n",
        "      self.drop = nn.Dropout()\n",
        "      # self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
        "  def forward(self, x): \n",
        "      x = self.pool(F.relu(self.conv1(x)))\n",
        "      x = self.pool(F.relu(self.conv2(x)))\n",
        "      x = self.pool(F.relu(self.conv3(x)))\n",
        "      x = self.pool(F.relu(self.conv4(x)))\n",
        "      x = self.pool(F.relu(self.conv5(x)))\n",
        "      # x = self.avgpool(x)\n",
        "      x = x.view(x.size()[0], 256 * 6 * 6)\n",
        "      x = self.drop(x)\n",
        "      x = F.relu(self.fc1(x))\n",
        "      x = self.drop(x)\n",
        "      x = F.relu(self.fc2(x))\n",
        "      x = self.fc3(x)\n",
        "      return x\n",
        "\n",
        "      \n",
        "class Classifier(nn.Module):\n",
        "  # TODO: implement me\n",
        "  def __init__(self):\n",
        "      super(Classifier, self).__init__()\n",
        "      # self.conv0 = nn.Conv2d(3, 256, 4)\n",
        "      self.conv1 = nn.Conv2d(3, 128, 5)#in_channel, out_chafeatunnel, kernel\n",
        "      self.conv2 = nn.Conv2d(128, 64, 5)#in_channel, out_chafeatunnel, kernel\n",
        "      self.conv3 = nn.Conv2d(64, 32, 3)\n",
        "      self.conv4 = nn.Conv2d(32, 16, 3)\n",
        "      self.pool = nn.MaxPool2d(2, 2)\n",
        "      self.fc1 = nn.Linear(16* 11 * 11, 120)\n",
        "      self.fc2 = nn.Linear(120, 84)\n",
        "      self.fc3 = nn.Linear(84, NUM_CLASSES)\n",
        "      self.drop = nn.Dropout(0.2)\n",
        "      \n",
        "  \n",
        "  def forward(self, x):\n",
        "\n",
        "      # x = self.pool(F.relu(self.conv0(x)))\n",
        "\n",
        "      x = self.pool(F.relu(self.conv1(x)))\n",
        "      x = self.pool(F.relu(self.conv2(x)))\n",
        "      x = self.pool(F.relu(self.conv3(x)))\n",
        "      x = self.pool(F.relu(self.conv4(x)))\n",
        "      # print('x size is', x.size())\n",
        "      x = x.view(x.size()[0], 16* 11 * 11)\n",
        "      x = F.relu(self.fc1(x))\n",
        "      x = self.drop(x)\n",
        "      x = F.relu(self.fc2(x))\n",
        "      x = self.fc3(x)\n",
        "\n",
        "      # x = self.pool(F.relu(self.conv1(x)))\n",
        "      # x = self.pool(F.relu(self.conv2(x)))\n",
        "      # x = self.pool(F.relu(self.conv3(x)))\n",
        "      # x = x.view(x.size()[0], 16 * 26 * 26)\n",
        "      # x = F.relu(self.fc1(x))\n",
        "      # x = F.relu(self.fc2(x))\n",
        "      # x = self.fc3(x)\n",
        "      return x\n",
        "\n",
        "\n"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoDieuhf8lKY"
      },
      "source": [
        "def train_classifier(train_loader, classifier, criterion, optimizer):\n",
        "    classifier.train()\n",
        "    loss_ = 0.0\n",
        "    losses = []\n",
        "    for i, (images, labels, _) in enumerate(train_loader):\n",
        "        # print(type(images), images.size())\n",
        "        # images = images.permute(0, 3, 1, 2)\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        logits = classifier(images)\n",
        "        loss = criterion(logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        losses.append(loss)\n",
        "    return torch.stack(losses).mean().item()"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wrwnvVb8lKb"
      },
      "source": [
        "def test_classifier(test_loader, classifier, criterion, print_ind_classes=True, print_total=True):\n",
        "    classifier.eval()\n",
        "    losses = []\n",
        "    with torch.no_grad():\n",
        "        y_true = np.zeros((0,21))\n",
        "        y_score = np.zeros((0,21))\n",
        "        for i, (images, labels, _) in enumerate(test_loader):\n",
        "            # images = images.permute(0, 3, 1, 2)\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            # print(type(images), images.size())\n",
        "\n",
        "            logits = classifier(images)\n",
        "            y_true = np.concatenate((y_true, labels.cpu().numpy()), axis=0)\n",
        "            y_score = np.concatenate((y_score, logits.cpu().numpy()), axis=0)\n",
        "            loss = criterion(logits, labels)\n",
        "            losses.append(loss.item())\n",
        "        aps = []\n",
        "        # ignore first class which is background\n",
        "        for i in range(1, y_true.shape[1]):\n",
        "            ap = average_precision_score(y_true[:, i], y_score[:, i])\n",
        "            if print_ind_classes:\n",
        "                print('-------  Class: {:<12}     AP: {:>8.4f}  -------'.format(VOC_CLASSES[i], ap))\n",
        "            aps.append(ap)\n",
        "        \n",
        "        mAP = np.mean(aps)\n",
        "        test_loss = np.mean(losses)\n",
        "        if print_total:\n",
        "            print('mAP: {0:.4f}'.format(mAP))\n",
        "            print('Avg loss: {}'.format(test_loss))\n",
        "        \n",
        "    return mAP, test_loss, aps"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d18yI2M78lKe"
      },
      "source": [
        "\n",
        "def plot_losses(train, val, test_frequency, num_epochs):\n",
        "    plt.plot(train, label=\"train\")\n",
        "    indices = [i for i in range(num_epochs) if ((i+1)%test_frequency == 0 or i ==0)]\n",
        "    plt.plot(indices, val, label=\"val\")\n",
        "    plt.title(\"Loss Plot\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    \n",
        "def plot_mAP(train, val, test_frequency, num_epochs):\n",
        "    indices = [i for i in range(num_epochs) if ((i+1)%test_frequency == 0 or i ==0)]\n",
        "    plt.plot(indices, train, label=\"train\")\n",
        "    plt.plot(indices, val, label=\"val\")\n",
        "    plt.title(\"mAP Plot\")\n",
        "    plt.ylabel(\"mAP\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKCxox7K8lKh"
      },
      "source": [
        "def train(classifier, num_epochs, train_loader, val_loader, criterion, optimizer, test_frequency=5):\n",
        "    train_losses = []\n",
        "    train_mAPs = []\n",
        "    val_losses = []\n",
        "    val_mAPs = []\n",
        "\n",
        "    for epoch in range(1,num_epochs+1):\n",
        "        print(\"Starting epoch number \" + str(epoch))\n",
        "        train_loss = train_classifier(train_loader, classifier, criterion, optimizer)\n",
        "        train_losses.append(train_loss)\n",
        "        print(\"Loss for Training on Epoch \" +str(epoch) + \" is \"+ str(train_loss))\n",
        "        if(epoch%test_frequency==0 or epoch==1):\n",
        "            mAP_train, _, _ = test_classifier(train_loader, classifier, criterion, False, False)\n",
        "            train_mAPs.append(mAP_train)\n",
        "            mAP_val, val_loss, _ = test_classifier(val_loader, classifier, criterion)\n",
        "            print('Evaluating classifier')\n",
        "            print(\"Mean Precision Score for Testing on Epoch \" +str(epoch) + \" is \"+ str(mAP_val))\n",
        "            val_losses.append(val_loss)\n",
        "            val_mAPs.append(mAP_val)\n",
        "    \n",
        "    return classifier, train_losses, val_losses, train_mAPs, val_mAPs"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuB4m_ou8lKk"
      },
      "source": [
        "# Developing Your Own Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9N8kQwF8lKl"
      },
      "source": [
        "### Goal\n",
        "To meet the benchmark for this assignment you will need to improve the network. Note you should have noticed pretrained Alenxt performs really well, but training Alexnet from scratch performs much worse. We hope you can design a better architecture over both the simple classifier and AlexNet to train from scratch.\n",
        "\n",
        "### How to start\n",
        "You may take inspiration from other published architectures and architectures discussed in lecture. However, you are NOT allowed to use predefined models (e.g. models from torchvision) or use pretrained weights. Training must be done from scratch with your own custom model.\n",
        "\n",
        "#### Some hints\n",
        "There are a variety of different approaches you should try to improve performance from the simple classifier:\n",
        "\n",
        "* Network architecture changes\n",
        "    * Number of layers: try adding layers to make your network deeper\n",
        "    * Batch normalization: adding batch norm between layers will likely give you a significant performance increase\n",
        "    * Residual connections: as you increase the depth of your network, you will find that having residual connections like those in ResNet architectures will be helpful\n",
        "* Optimizer: Instead of plain SGD, you may want to add a learning rate schedule, add momentum, or use one of the other optimizers you have learned about like Adam. Check the `torch.optim` package for other optimizers\n",
        "* Data augmentation: You should use the `torchvision.transforms` module to try adding random resized crops and horizontal flips of the input data. Check `transforms.RandomResizedCrop` and `transforms.RandomHorizontalFlip` for this. Feel free to apply more [transforms](https://pytorch.org/docs/stable/torchvision/transforms.html) for data augmentation which can lead to better performance. \n",
        "* Epochs: Once you have found a generally good hyperparameter setting try training for more epochs\n",
        "* Loss function: You might want to add weighting to the `MultiLabelSoftMarginLoss` for classes that are less well represented or experiment with a different loss function\n",
        "\n",
        "\n",
        "\n",
        "#### Note\n",
        "We will soon be providing some initial expectations of mAP values as a function of epoch so you can get an early idea whether your implementation works without waiting a long time for training to converge.\n",
        "\n",
        "### What to submit \n",
        "Submit your best model to Kaggle and save all plots for the writeup.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tj4X-groxkta"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                     std= [0.229, 0.224, 0.225])\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "            transforms.Resize(227),\n",
        "            transforms.CenterCrop(227),\n",
        "            transforms.ToTensor(),\n",
        "            normalize\n",
        "        ])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "            transforms.Resize(227),\n",
        "            transforms.CenterCrop(227),\n",
        "            transforms.ToTensor(),\n",
        "            normalize,\n",
        "        ])\n",
        "ds_train = VocDataset('/content/VOCdevkit_2007/VOC2007','train',train_transform)\n",
        "ds_val = VocDataset('/content/VOCdevkit_2007/VOC2007','val',test_transform)\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hu2rZ6h_8lKp"
      },
      "source": [
        "num_epochs = 5\n",
        "test_frequency = 5\n",
        "batch_size = 64\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=ds_train,\n",
        "                                               batch_size=batch_size, \n",
        "                                               shuffle=True,\n",
        "                                               num_workers=1)\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(dataset=ds_val,\n",
        "                                               batch_size=batch_size, \n",
        "                                               shuffle=True,\n",
        "                                               num_workers=1)\n",
        "\n",
        "# test_loader = torch.utils.data.DataLoader(dataset=ds_test,\n",
        "#                                                batch_size=batch_size, \n",
        "#                                                shuffle=False,\n",
        "#                                                num_workers=1)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNDaIgap8lKt",
        "outputId": "06f29afd-ea96-49ef-ca60-2047f59c842b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "source": [
        "# TODO: Run your own classifier here\n",
        "classifier = Classifier().to(device)\n",
        "\n",
        "criterion = nn.MultiLabelSoftMarginLoss()\n",
        "optimizer = torch.optim.SGD(classifier.parameters(), lr=0.01, momentum=0.9)\n",
        "# optimizer = torch.optim.Adam(classifier.parameters(), lr=1e-4)\n",
        "\n",
        "classifier, train_losses, val_losses, train_mAPs, val_mAPs = train(classifier, num_epochs, train_loader, val_loader, criterion, optimizer, test_frequency)\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting epoch number 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-872993b90dd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# optimizer = torch.optim.Adam(classifier.parameters(), lr=1e-4)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_mAPs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_mAPs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_frequency\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-9-cfae9759689b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(classifier, num_epochs, train_loader, val_loader, criterion, optimizer, test_frequency)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting epoch number \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss for Training on Epoch \"\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" is \"\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-f8e3bb9617c0>\u001b[0m in \u001b[0;36mtrain_classifier\u001b[0;34m(train_loader, classifier, criterion, optimizer)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mloss_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;31m# print(type(images), images.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m# images = images.permute(0, 3, 1, 2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    806\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    809\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                 \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZx6XQkh8lKw"
      },
      "source": [
        "plot_losses(train_losses, val_losses, test_frequency, num_epochs)\n",
        "plot_mAP(train_mAPs, val_mAPs, test_frequency, num_epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bs_AN04H8lKy"
      },
      "source": [
        "mAP_test, test_loss, test_aps = test_classifier(test_loader, classifier, criterion)\n",
        "print(mAP_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfwdBpBK8lK0"
      },
      "source": [
        "torch.save(classifier.state_dict(), './voc_my_best_classifier.pth')\n",
        "output_submission_csv('my_solution.csv', test_aps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JdE1mIU8lK3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67WhDasKPgG6"
      },
      "source": [
        "# Image Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXb1tFfbPiv9"
      },
      "source": [
        "class ImgAugTransform:\n",
        "  def __init__(self):\n",
        "    self.aug = iaa.Sequential([\n",
        "        iaa.Resize(227)\n",
        "        # iaa.Sometimes(0.25, iaa.GaussianBlur(sigma=(0, 3.0))),\n",
        "        # iaa.Fliplr(0.5),\n",
        "        # iaa.Affine(rotate=(-20, 20), mode='symmetric'),\n",
        "        # iaa.Sometimes(0.25,\n",
        "        #               iaa.OneOf([iaa.Dropout(p=(0, 0.1)),\n",
        "        #                          iaa.CoarseDropout(0.1, size_percent=0.5)])),\n",
        "        # iaa.AddToHueAndSaturation(value=(-20, 20), per_channel=True)\n",
        "    ])\n",
        "      \n",
        "  def __call__(self, img):\n",
        "    img = np.array(img)\n",
        "    return self.aug.augment_image(img)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                     std= [0.229, 0.224, 0.225])\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize(227),\n",
        "    transforms.ColorJitter(hue=.05, saturation=.05, brightness= 0.05, contrast = 0.05),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(20),\n",
        "    transforms.CenterCrop(227),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    normalize,\n",
        "])\n",
        "    \n",
        "# train_transform = ImgAugTransform()\n",
        "test_transform = transforms.Compose([\n",
        "            transforms.Resize(227),\n",
        "            transforms.CenterCrop(227),\n",
        "            transforms.ToTensor(),\n",
        "            normalize,\n",
        "        ])"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqWl51bwa1VR"
      },
      "source": [
        "\n",
        "ds_train = VocDataset('/content/VOCdevkit_2007/VOC2007','train',train_transform)\n",
        "ds_val = VocDataset('/content/VOCdevkit_2007/VOC2007','val',test_transform)\n"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Snp_p26Sk6CV"
      },
      "source": [
        "num_epochs = 5\n",
        "test_frequency = 5\n",
        "batch_size = 64\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=ds_train,\n",
        "                                               batch_size=batch_size, \n",
        "                                               shuffle=True,\n",
        "                                               num_workers=1)\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(dataset=ds_val,\n",
        "                                               batch_size=batch_size, \n",
        "                                               shuffle=True,\n",
        "                                               num_workers=1)\n",
        "\n",
        "# test_loader = torch.utils.data.DataLoader(dataset=ds_test,\n",
        "#                                                batch_size=batch_size, \n",
        "#                                                shuffle=False,\n",
        "#                                                num_workers=1)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2Si9Mthk9KF",
        "outputId": "1e215d20-9ac2-471b-ede9-a71b62618875",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# TODO: Run your own classifier here\n",
        "classifier = Classifier().to(device)\n",
        "\n",
        "criterion = nn.MultiLabelSoftMarginLoss()\n",
        "optimizer = torch.optim.SGD(classifier.parameters(), lr=0.01, momentum=0.9)\n",
        "# optimizer = torch.optim.Adam(classifier.parameters(), lr=1e-4)\n",
        "\n",
        "classifier, train_losses, val_losses, train_mAPs, val_mAPs = train(classifier, num_epochs, train_loader, val_loader, criterion, optimizer, test_frequency)\n"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting epoch number 1\n",
            "Loss for Training on Epoch 1 is 0.6724071502685547\n",
            "-------  Class: aeroplane        AP:   0.0490  -------\n",
            "-------  Class: bicycle          AP:   0.0450  -------\n",
            "-------  Class: bird             AP:   0.1028  -------\n",
            "-------  Class: boat             AP:   0.0574  -------\n",
            "-------  Class: bottle           AP:   0.0410  -------\n",
            "-------  Class: bus              AP:   0.0297  -------\n",
            "-------  Class: car              AP:   0.1305  -------\n",
            "-------  Class: cat              AP:   0.0849  -------\n",
            "-------  Class: chair            AP:   0.1057  -------\n",
            "-------  Class: cow              AP:   0.0332  -------\n",
            "-------  Class: diningtable      AP:   0.0559  -------\n",
            "-------  Class: dog              AP:   0.1096  -------\n",
            "-------  Class: horse            AP:   0.0668  -------\n",
            "-------  Class: motorbike        AP:   0.0382  -------\n",
            "-------  Class: person           AP:   0.3410  -------\n",
            "-------  Class: pottedplant      AP:   0.0446  -------\n",
            "-------  Class: sheep            AP:   0.0259  -------\n",
            "-------  Class: sofa             AP:   0.0611  -------\n",
            "-------  Class: train            AP:   0.0398  -------\n",
            "-------  Class: tvmonitor        AP:   0.0521  -------\n",
            "mAP: 0.0757\n",
            "Avg loss: 0.646646012365818\n",
            "Evaluating classifier\n",
            "Mean Precision Score for Testing on Epoch 1 is 0.075717268622313\n",
            "Starting epoch number 2\n",
            "Loss for Training on Epoch 2 is 0.41052255034446716\n",
            "Starting epoch number 3\n",
            "Loss for Training on Epoch 3 is 0.24883131682872772\n",
            "Starting epoch number 4\n",
            "Loss for Training on Epoch 4 is 0.24687333405017853\n",
            "Starting epoch number 5\n",
            "Loss for Training on Epoch 5 is 0.24571307003498077\n",
            "-------  Class: aeroplane        AP:   0.0877  -------\n",
            "-------  Class: bicycle          AP:   0.0466  -------\n",
            "-------  Class: bird             AP:   0.1232  -------\n",
            "-------  Class: boat             AP:   0.0867  -------\n",
            "-------  Class: bottle           AP:   0.0443  -------\n",
            "-------  Class: bus              AP:   0.0284  -------\n",
            "-------  Class: car              AP:   0.1100  -------\n",
            "-------  Class: cat              AP:   0.0904  -------\n",
            "-------  Class: chair            AP:   0.1224  -------\n",
            "-------  Class: cow              AP:   0.0319  -------\n",
            "-------  Class: diningtable      AP:   0.0566  -------\n",
            "-------  Class: dog              AP:   0.1199  -------\n",
            "-------  Class: horse            AP:   0.0514  -------\n",
            "-------  Class: motorbike        AP:   0.0415  -------\n",
            "-------  Class: person           AP:   0.3865  -------\n",
            "-------  Class: pottedplant      AP:   0.0475  -------\n",
            "-------  Class: sheep            AP:   0.0294  -------\n",
            "-------  Class: sofa             AP:   0.0958  -------\n",
            "-------  Class: train            AP:   0.0362  -------\n",
            "-------  Class: tvmonitor        AP:   0.0500  -------\n",
            "mAP: 0.0843\n",
            "Avg loss: 0.23890670239925385\n",
            "Evaluating classifier\n",
            "Mean Precision Score for Testing on Epoch 5 is 0.08431725256328715\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYU_dyPZkwtH",
        "outputId": "c67c30d4-13e5-4da0-bb4d-862628151836",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        }
      },
      "source": [
        "# TODO: Run your own classifier here\n",
        "classifier = Alexnet().to(device)\n",
        "\n",
        "criterion = nn.MultiLabelSoftMarginLoss()\n",
        "optimizer = torch.optim.SGD(classifier.parameters(), lr=0.01, momentum=0.9)\n",
        "# optimizer = torch.optim.Adam(classifier.parameters(), lr=1e-4)\n",
        "\n",
        "classifier, train_losses, val_losses, train_mAPs, val_mAPs = train(classifier, num_epochs, train_loader, val_loader, criterion, optimizer, test_frequency)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-5eb7cef220e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# TODO: Run your own classifier here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAlexnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultiLabelSoftMarginLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Alexnet' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_ESx_CbFGPE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}